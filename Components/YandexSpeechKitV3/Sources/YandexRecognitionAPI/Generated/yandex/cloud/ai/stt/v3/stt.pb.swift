// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: yandex/cloud/ai/stt/v3/stt.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

enum Speechkit_Stt_V3_CodeType: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case unspecified // = 0

  ///all good
  case working // = 1

  ///for example, if speech is sent not in real time. or unknown context (and we've made fallback)
  case warning // = 2

  ///after session was closed
  case closed // = 3
  case UNRECOGNIZED(Int)

  init() {
    self = .unspecified
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .unspecified
    case 1: self = .working
    case 2: self = .warning
    case 3: self = .closed
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .unspecified: return 0
    case .working: return 1
    case .warning: return 2
    case .closed: return 3
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Speechkit_Stt_V3_CodeType: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Speechkit_Stt_V3_CodeType] = [
    .unspecified,
    .working,
    .warning,
    .closed,
  ]
}

#endif  // swift(>=4.2)

/// options
struct Speechkit_Stt_V3_TextNormalizationOptions {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var textNormalization: Speechkit_Stt_V3_TextNormalizationOptions.TextNormalization = .unspecified

  /// Filter profanity (default: false)
  var profanityFilter: Bool = false

  /// Rewrite text in literature style (default: false)
  var literatureText: Bool = false

  var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Normalization 
  enum TextNormalization: SwiftProtobuf.Enum {
    typealias RawValue = Int
    case unspecified // = 0

    /// Enable normalization
    case enabled // = 1

    /// Disable normalization
    case disabled // = 2
    case UNRECOGNIZED(Int)

    init() {
      self = .unspecified
    }

    init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .enabled
      case 2: self = .disabled
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .enabled: return 1
      case .disabled: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  init() {}
}

#if swift(>=4.2)

extension Speechkit_Stt_V3_TextNormalizationOptions.TextNormalization: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Speechkit_Stt_V3_TextNormalizationOptions.TextNormalization] = [
    .unspecified,
    .enabled,
    .disabled,
  ]
}

#endif  // swift(>=4.2)

struct Speechkit_Stt_V3_DefaultEouClassifier {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// EOU sensitivity.  Currently two levels, faster with more error and more conservative (our default)
  var type: Speechkit_Stt_V3_DefaultEouClassifier.EouSensitivity = .unspecified

  /// hint for max pause between words. Our EoU detector could use this information to distinguish between end of utterance and slow speech (like one <long pause> two <long pause> three, etc)
  var maxPauseBetweenWordsHintMs: Int64 = 0

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum EouSensitivity: SwiftProtobuf.Enum {
    typealias RawValue = Int
    case unspecified // = 0
    case `default` // = 1
    case high // = 2
    case UNRECOGNIZED(Int)

    init() {
      self = .unspecified
    }

    init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .default
      case 2: self = .high
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .default: return 1
      case .high: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  init() {}
}

#if swift(>=4.2)

extension Speechkit_Stt_V3_DefaultEouClassifier.EouSensitivity: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Speechkit_Stt_V3_DefaultEouClassifier.EouSensitivity] = [
    .unspecified,
    .default,
    .high,
  ]
}

#endif  // swift(>=4.2)

/// use EOU provided by user
struct Speechkit_Stt_V3_ExternalEouClassifier {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

struct Speechkit_Stt_V3_EouClassifierOptions {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// type of EOU classifier.
  var classifier: Speechkit_Stt_V3_EouClassifierOptions.OneOf_Classifier? = nil

  ///EOU classifier provided by SpeechKit. Default
  var defaultClassifier: Speechkit_Stt_V3_DefaultEouClassifier {
    get {
      if case .defaultClassifier(let v)? = classifier {return v}
      return Speechkit_Stt_V3_DefaultEouClassifier()
    }
    set {classifier = .defaultClassifier(newValue)}
  }

  ///EoU is enforced by external messages from user
  var externalClassifier: Speechkit_Stt_V3_ExternalEouClassifier {
    get {
      if case .externalClassifier(let v)? = classifier {return v}
      return Speechkit_Stt_V3_ExternalEouClassifier()
    }
    set {classifier = .externalClassifier(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  /// type of EOU classifier.
  enum OneOf_Classifier: Equatable {
    ///EOU classifier provided by SpeechKit. Default
    case defaultClassifier(Speechkit_Stt_V3_DefaultEouClassifier)
    ///EoU is enforced by external messages from user
    case externalClassifier(Speechkit_Stt_V3_ExternalEouClassifier)

  #if !swift(>=4.1)
    static func ==(lhs: Speechkit_Stt_V3_EouClassifierOptions.OneOf_Classifier, rhs: Speechkit_Stt_V3_EouClassifierOptions.OneOf_Classifier) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.defaultClassifier, .defaultClassifier): return {
        guard case .defaultClassifier(let l) = lhs, case .defaultClassifier(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.externalClassifier, .externalClassifier): return {
        guard case .externalClassifier(let l) = lhs, case .externalClassifier(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  init() {}
}

/// RAW Audio format spec (no container to infer type). used in AudioFormat options
struct Speechkit_Stt_V3_RawAudio {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///  type of audio encoding
  var audioEncoding: Speechkit_Stt_V3_RawAudio.AudioEncoding = .unspecified

  ///  PCM sample rate
  var sampleRateHertz: Int64 = 0

  ///  PCM channel count. Currently only single channel audio is supported in real-time recognition
  var audioChannelCount: Int64 = 0

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum AudioEncoding: SwiftProtobuf.Enum {
    typealias RawValue = Int
    case unspecified // = 0
    case linear16Pcm // = 1
    case UNRECOGNIZED(Int)

    init() {
      self = .unspecified
    }

    init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .linear16Pcm
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .linear16Pcm: return 1
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  init() {}
}

#if swift(>=4.2)

extension Speechkit_Stt_V3_RawAudio.AudioEncoding: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Speechkit_Stt_V3_RawAudio.AudioEncoding] = [
    .unspecified,
    .linear16Pcm,
  ]
}

#endif  // swift(>=4.2)

/// Audio with fixed type in container. used in AudioFormat options
struct Speechkit_Stt_V3_ContainerAudio {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///  type of audio container
  var containerAudioType: Speechkit_Stt_V3_ContainerAudio.ContainerAudioType = .unspecified

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum ContainerAudioType: SwiftProtobuf.Enum {
    typealias RawValue = Int
    case unspecified // = 0
    case wav // = 1
    case oggOpus // = 2
    case mp3 // = 3
    case UNRECOGNIZED(Int)

    init() {
      self = .unspecified
    }

    init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .wav
      case 2: self = .oggOpus
      case 3: self = .mp3
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .wav: return 1
      case .oggOpus: return 2
      case .mp3: return 3
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  init() {}
}

#if swift(>=4.2)

extension Speechkit_Stt_V3_ContainerAudio.ContainerAudioType: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Speechkit_Stt_V3_ContainerAudio.ContainerAudioType] = [
    .unspecified,
    .wav,
    .oggOpus,
    .mp3,
  ]
}

#endif  // swift(>=4.2)

/// audio format options
struct Speechkit_Stt_V3_AudioFormatOptions {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var audioFormat: Speechkit_Stt_V3_AudioFormatOptions.OneOf_AudioFormat? = nil

  ///    audio without container
  var rawAudio: Speechkit_Stt_V3_RawAudio {
    get {
      if case .rawAudio(let v)? = audioFormat {return v}
      return Speechkit_Stt_V3_RawAudio()
    }
    set {audioFormat = .rawAudio(newValue)}
  }

  ///    audio is wrapped in container
  var containerAudio: Speechkit_Stt_V3_ContainerAudio {
    get {
      if case .containerAudio(let v)? = audioFormat {return v}
      return Speechkit_Stt_V3_ContainerAudio()
    }
    set {audioFormat = .containerAudio(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum OneOf_AudioFormat: Equatable {
    ///    audio without container
    case rawAudio(Speechkit_Stt_V3_RawAudio)
    ///    audio is wrapped in container
    case containerAudio(Speechkit_Stt_V3_ContainerAudio)

  #if !swift(>=4.1)
    static func ==(lhs: Speechkit_Stt_V3_AudioFormatOptions.OneOf_AudioFormat, rhs: Speechkit_Stt_V3_AudioFormatOptions.OneOf_AudioFormat) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.rawAudio, .rawAudio): return {
        guard case .rawAudio(let l) = lhs, case .rawAudio(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.containerAudio, .containerAudio): return {
        guard case .containerAudio(let l) = lhs, case .containerAudio(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  init() {}
}

struct Speechkit_Stt_V3_LanguageRestrictionOptions {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var restrictionType: Speechkit_Stt_V3_LanguageRestrictionOptions.LanguageRestrictionType = .unspecified

  var languageCode: [String] = []

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum LanguageRestrictionType: SwiftProtobuf.Enum {
    typealias RawValue = Int
    case unspecified // = 0
    case whitelist // = 1
    case blacklist // = 2
    case UNRECOGNIZED(Int)

    init() {
      self = .unspecified
    }

    init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .whitelist
      case 2: self = .blacklist
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .whitelist: return 1
      case .blacklist: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  init() {}
}

#if swift(>=4.2)

extension Speechkit_Stt_V3_LanguageRestrictionOptions.LanguageRestrictionType: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Speechkit_Stt_V3_LanguageRestrictionOptions.LanguageRestrictionType] = [
    .unspecified,
    .whitelist,
    .blacklist,
  ]
}

#endif  // swift(>=4.2)

struct Speechkit_Stt_V3_RecognitionModelOptions {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///  reserved for future, do not use
  var model: String = String()

  ///  config for input audio
  var audioFormat: Speechkit_Stt_V3_AudioFormatOptions {
    get {return _audioFormat ?? Speechkit_Stt_V3_AudioFormatOptions()}
    set {_audioFormat = newValue}
  }
  /// Returns true if `audioFormat` has been explicitly set.
  var hasAudioFormat: Bool {return self._audioFormat != nil}
  /// Clears the value of `audioFormat`. Subsequent reads from it will return its default value.
  mutating func clearAudioFormat() {self._audioFormat = nil}

  ///  text normalization options
  var textNormalization: Speechkit_Stt_V3_TextNormalizationOptions {
    get {return _textNormalization ?? Speechkit_Stt_V3_TextNormalizationOptions()}
    set {_textNormalization = newValue}
  }
  /// Returns true if `textNormalization` has been explicitly set.
  var hasTextNormalization: Bool {return self._textNormalization != nil}
  /// Clears the value of `textNormalization`. Subsequent reads from it will return its default value.
  mutating func clearTextNormalization() {self._textNormalization = nil}

  /// possible languages in audio
  var languageRestriction: Speechkit_Stt_V3_LanguageRestrictionOptions {
    get {return _languageRestriction ?? Speechkit_Stt_V3_LanguageRestrictionOptions()}
    set {_languageRestriction = newValue}
  }
  /// Returns true if `languageRestriction` has been explicitly set.
  var hasLanguageRestriction: Bool {return self._languageRestriction != nil}
  /// Clears the value of `languageRestriction`. Subsequent reads from it will return its default value.
  mutating func clearLanguageRestriction() {self._languageRestriction = nil}

  ///how to deal with audio data (in real time, after all data is received, etc). Default is REAL_TIME
  var audioProcessingType: Speechkit_Stt_V3_RecognitionModelOptions.AudioProcessingType = .unspecified

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum AudioProcessingType: SwiftProtobuf.Enum {
    typealias RawValue = Int
    case unspecified // = 0
    case realTime // = 1
    case fullData // = 2
    case UNRECOGNIZED(Int)

    init() {
      self = .unspecified
    }

    init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .realTime
      case 2: self = .fullData
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .realTime: return 1
      case .fullData: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  init() {}

  fileprivate var _audioFormat: Speechkit_Stt_V3_AudioFormatOptions? = nil
  fileprivate var _textNormalization: Speechkit_Stt_V3_TextNormalizationOptions? = nil
  fileprivate var _languageRestriction: Speechkit_Stt_V3_LanguageRestrictionOptions? = nil
}

#if swift(>=4.2)

extension Speechkit_Stt_V3_RecognitionModelOptions.AudioProcessingType: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Speechkit_Stt_V3_RecognitionModelOptions.AudioProcessingType] = [
    .unspecified,
    .realTime,
    .fullData,
  ]
}

#endif  // swift(>=4.2)

struct Speechkit_Stt_V3_StreamingOptions {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///  configuration for speech recognition model
  var recognitionModel: Speechkit_Stt_V3_RecognitionModelOptions {
    get {return _recognitionModel ?? Speechkit_Stt_V3_RecognitionModelOptions()}
    set {_recognitionModel = newValue}
  }
  /// Returns true if `recognitionModel` has been explicitly set.
  var hasRecognitionModel: Bool {return self._recognitionModel != nil}
  /// Clears the value of `recognitionModel`. Subsequent reads from it will return its default value.
  mutating func clearRecognitionModel() {self._recognitionModel = nil}

  ///  configuration for end of utterance detection model
  var eouClassifier: Speechkit_Stt_V3_EouClassifierOptions {
    get {return _eouClassifier ?? Speechkit_Stt_V3_EouClassifierOptions()}
    set {_eouClassifier = newValue}
  }
  /// Returns true if `eouClassifier` has been explicitly set.
  var hasEouClassifier: Bool {return self._eouClassifier != nil}
  /// Clears the value of `eouClassifier`. Subsequent reads from it will return its default value.
  mutating func clearEouClassifier() {self._eouClassifier = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _recognitionModel: Speechkit_Stt_V3_RecognitionModelOptions? = nil
  fileprivate var _eouClassifier: Speechkit_Stt_V3_EouClassifierOptions? = nil
}

/// data chunk with audio
struct Speechkit_Stt_V3_AudioChunk {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///  bytes with audio data
  var data: Data = Data()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

struct Speechkit_Stt_V3_SilenceChunk {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///  duration of silence chunk in ms
  var durationMs: Int64 = 0

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// force EOU
struct Speechkit_Stt_V3_Eou {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// streaming audio request
/// Events are control messages from user
/// first message should be session options
/// the next messages are audio data chunks or control messages
struct Speechkit_Stt_V3_StreamingRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var event: Speechkit_Stt_V3_StreamingRequest.OneOf_Event? = nil

  ///    Session options. should be first message from user
  var sessionOptions: Speechkit_Stt_V3_StreamingOptions {
    get {
      if case .sessionOptions(let v)? = event {return v}
      return Speechkit_Stt_V3_StreamingOptions()
    }
    set {event = .sessionOptions(newValue)}
  }

  ///    chunk with audio data
  var chunk: Speechkit_Stt_V3_AudioChunk {
    get {
      if case .chunk(let v)? = event {return v}
      return Speechkit_Stt_V3_AudioChunk()
    }
    set {event = .chunk(newValue)}
  }

  ///    chunk with silence
  var silenceChunk: Speechkit_Stt_V3_SilenceChunk {
    get {
      if case .silenceChunk(let v)? = event {return v}
      return Speechkit_Stt_V3_SilenceChunk()
    }
    set {event = .silenceChunk(newValue)}
  }

  ///    request to end current utterance. Works only with external EoU detector
  var eou: Speechkit_Stt_V3_Eou {
    get {
      if case .eou(let v)? = event {return v}
      return Speechkit_Stt_V3_Eou()
    }
    set {event = .eou(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum OneOf_Event: Equatable {
    ///    Session options. should be first message from user
    case sessionOptions(Speechkit_Stt_V3_StreamingOptions)
    ///    chunk with audio data
    case chunk(Speechkit_Stt_V3_AudioChunk)
    ///    chunk with silence
    case silenceChunk(Speechkit_Stt_V3_SilenceChunk)
    ///    request to end current utterance. Works only with external EoU detector
    case eou(Speechkit_Stt_V3_Eou)

  #if !swift(>=4.1)
    static func ==(lhs: Speechkit_Stt_V3_StreamingRequest.OneOf_Event, rhs: Speechkit_Stt_V3_StreamingRequest.OneOf_Event) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.sessionOptions, .sessionOptions): return {
        guard case .sessionOptions(let l) = lhs, case .sessionOptions(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.chunk, .chunk): return {
        guard case .chunk(let l) = lhs, case .chunk(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.silenceChunk, .silenceChunk): return {
        guard case .silenceChunk(let l) = lhs, case .silenceChunk(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.eou, .eou): return {
        guard case .eou(let l) = lhs, case .eou(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  init() {}
}

/// recognized word
struct Speechkit_Stt_V3_Word {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///  word text
  var text: String = String()

  ///  estimation of word start time in ms
  var startTimeMs: Int64 = 0

  ///  estimation of word end time in ms
  var endTimeMs: Int64 = 0

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

///recognition of specific time frame
struct Speechkit_Stt_V3_Alternative {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///  words in time frame
  var words: [Speechkit_Stt_V3_Word] = []

  ///  text in time frame
  var text: String = String()

  ///  start of time frame
  var startTimeMs: Int64 = 0

  ///  end of time frame
  var endTimeMs: Int64 = 0

  ///  hypothesis confidence. Currently is not used
  var confidence: Double = 0

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

///Update information from
struct Speechkit_Stt_V3_EouUpdate {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///  end of utterance estimated time
  var timeMs: Int64 = 0

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// update of hypothesis
struct Speechkit_Stt_V3_AlternativeUpdate {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///  list of hypothesis for timeframes
  var alternatives: [Speechkit_Stt_V3_Alternative] = []

  ///  tag for distinguish audio channels.
  var channelTag: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// AudioCursors are state of ASR recognition stream
struct Speechkit_Stt_V3_AudioCursors {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// amount of audio chunks server received. This cursor is moved after each audio chunk was received by server.
  var receivedDataMs: Int64 = 0

  /// input stream reset data
  var resetTimeMs: Int64 = 0

  ///  how much audio was processed. This time includes trimming silences as well. This cursor is moved after server received enough data
  ///  to update recognition results (includes silence as well)
  var partialTimeMs: Int64 = 0

  ///  Time of last final. This cursor is moved when server decides that recognition from start of audio until final_time_ms will not change anymore
  ///  usually this even is followed by EOU detection (but this could change in future)
  var finalTimeMs: Int64 = 0

  ///  This is index of last final server send. Incremented after each new final.
  var finalIndex: Int64 = 0

  ///  Estimated time of EOU. Cursor is updated after each new EOU is sent
  ///  For external classifier this equals to received_data_ms at the moment EOU event arrives
  ///  For internal classifier this is estimation of time. The time is not exact and has the same guarantees as word timings
  var eouTimeMs: Int64 = 0

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

///refinement for final hypo. For example, text normalization is refinement.
struct Speechkit_Stt_V3_FinalRefinement {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///  index of final for which server sends additional information
  var finalIndex: Int64 = 0

  ///  type of refinement
  var type: Speechkit_Stt_V3_FinalRefinement.OneOf_Type? = nil

  ///   normalized text instead of raw one
  var normalizedText: Speechkit_Stt_V3_AlternativeUpdate {
    get {
      if case .normalizedText(let v)? = type {return v}
      return Speechkit_Stt_V3_AlternativeUpdate()
    }
    set {type = .normalizedText(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  ///  type of refinement
  enum OneOf_Type: Equatable {
    ///   normalized text instead of raw one
    case normalizedText(Speechkit_Stt_V3_AlternativeUpdate)

  #if !swift(>=4.1)
    static func ==(lhs: Speechkit_Stt_V3_FinalRefinement.OneOf_Type, rhs: Speechkit_Stt_V3_FinalRefinement.OneOf_Type) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.normalizedText, .normalizedText): return {
        guard case .normalizedText(let l) = lhs, case .normalizedText(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      }
    }
  #endif
  }

  init() {}
}

///status message
struct Speechkit_Stt_V3_StatusCode {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///  code type
  var codeType: Speechkit_Stt_V3_CodeType = .unspecified

  ///  human readable message
  var message: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

///session identifier
struct Speechkit_Stt_V3_SessionUuid {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///  internal session identifier
  var uuid: String = String()

  ///  user session identifier
  var userRequestID: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// responses from server
/// each response contains session uuid
/// AudioCursors
/// plus specific even
struct Speechkit_Stt_V3_StreamingResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  ///  session identifier
  var sessionUuid: Speechkit_Stt_V3_SessionUuid {
    get {return _sessionUuid ?? Speechkit_Stt_V3_SessionUuid()}
    set {_sessionUuid = newValue}
  }
  /// Returns true if `sessionUuid` has been explicitly set.
  var hasSessionUuid: Bool {return self._sessionUuid != nil}
  /// Clears the value of `sessionUuid`. Subsequent reads from it will return its default value.
  mutating func clearSessionUuid() {self._sessionUuid = nil}

  ///  progress bar for stream session recognition: how many data we obtained; final and partial times; etc
  var audioCursors: Speechkit_Stt_V3_AudioCursors {
    get {return _audioCursors ?? Speechkit_Stt_V3_AudioCursors()}
    set {_audioCursors = newValue}
  }
  /// Returns true if `audioCursors` has been explicitly set.
  var hasAudioCursors: Bool {return self._audioCursors != nil}
  /// Clears the value of `audioCursors`. Subsequent reads from it will return its default value.
  mutating func clearAudioCursors() {self._audioCursors = nil}

  /// wall clock on server side. This is time when server wrote results to stream
  var responseWallTimeMs: Int64 = 0

  var event: Speechkit_Stt_V3_StreamingResponse.OneOf_Event? = nil

  ///    partial results, server will send them regularly after enough audio data was received from user. This are current text estimation
  ///    from final_time_ms to partial_time_ms. Could change after new data will arrive
  var partial: Speechkit_Stt_V3_AlternativeUpdate {
    get {
      if case .partial(let v)? = event {return v}
      return Speechkit_Stt_V3_AlternativeUpdate()
    }
    set {event = .partial(newValue)}
  }

  ///    final results, the recognition is now fixed until final_time_ms. For now, final is sent only if the EOU event was triggered. This could be change in future releases
  var final: Speechkit_Stt_V3_AlternativeUpdate {
    get {
      if case .final(let v)? = event {return v}
      return Speechkit_Stt_V3_AlternativeUpdate()
    }
    set {event = .final(newValue)}
  }

  ///  After EOU classifier, send the message with final, send the EouUpdate with time of EOU
  ///  before eou_update we send final with the same time. there could be several finals before eou update
  var eouUpdate: Speechkit_Stt_V3_EouUpdate {
    get {
      if case .eouUpdate(let v)? = event {return v}
      return Speechkit_Stt_V3_EouUpdate()
    }
    set {event = .eouUpdate(newValue)}
  }

  ///    For each final, if normalization is enabled, sent the normalized text (or some other advanced post-processing).
  ///    Final normalization will introduce additional latency
  var finalRefinement: Speechkit_Stt_V3_FinalRefinement {
    get {
      if case .finalRefinement(let v)? = event {return v}
      return Speechkit_Stt_V3_FinalRefinement()
    }
    set {event = .finalRefinement(newValue)}
  }

  ///    Status messages, send by server with fixed interval (keep-alive)
  var statusCode: Speechkit_Stt_V3_StatusCode {
    get {
      if case .statusCode(let v)? = event {return v}
      return Speechkit_Stt_V3_StatusCode()
    }
    set {event = .statusCode(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum OneOf_Event: Equatable {
    ///    partial results, server will send them regularly after enough audio data was received from user. This are current text estimation
    ///    from final_time_ms to partial_time_ms. Could change after new data will arrive
    case partial(Speechkit_Stt_V3_AlternativeUpdate)
    ///    final results, the recognition is now fixed until final_time_ms. For now, final is sent only if the EOU event was triggered. This could be change in future releases
    case final(Speechkit_Stt_V3_AlternativeUpdate)
    ///  After EOU classifier, send the message with final, send the EouUpdate with time of EOU
    ///  before eou_update we send final with the same time. there could be several finals before eou update
    case eouUpdate(Speechkit_Stt_V3_EouUpdate)
    ///    For each final, if normalization is enabled, sent the normalized text (or some other advanced post-processing).
    ///    Final normalization will introduce additional latency
    case finalRefinement(Speechkit_Stt_V3_FinalRefinement)
    ///    Status messages, send by server with fixed interval (keep-alive)
    case statusCode(Speechkit_Stt_V3_StatusCode)

  #if !swift(>=4.1)
    static func ==(lhs: Speechkit_Stt_V3_StreamingResponse.OneOf_Event, rhs: Speechkit_Stt_V3_StreamingResponse.OneOf_Event) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.partial, .partial): return {
        guard case .partial(let l) = lhs, case .partial(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.final, .final): return {
        guard case .final(let l) = lhs, case .final(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.eouUpdate, .eouUpdate): return {
        guard case .eouUpdate(let l) = lhs, case .eouUpdate(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.finalRefinement, .finalRefinement): return {
        guard case .finalRefinement(let l) = lhs, case .finalRefinement(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.statusCode, .statusCode): return {
        guard case .statusCode(let l) = lhs, case .statusCode(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  init() {}

  fileprivate var _sessionUuid: Speechkit_Stt_V3_SessionUuid? = nil
  fileprivate var _audioCursors: Speechkit_Stt_V3_AudioCursors? = nil
}

#if swift(>=5.5) && canImport(_Concurrency)
extension Speechkit_Stt_V3_CodeType: @unchecked Sendable {}
extension Speechkit_Stt_V3_TextNormalizationOptions: @unchecked Sendable {}
extension Speechkit_Stt_V3_TextNormalizationOptions.TextNormalization: @unchecked Sendable {}
extension Speechkit_Stt_V3_DefaultEouClassifier: @unchecked Sendable {}
extension Speechkit_Stt_V3_DefaultEouClassifier.EouSensitivity: @unchecked Sendable {}
extension Speechkit_Stt_V3_ExternalEouClassifier: @unchecked Sendable {}
extension Speechkit_Stt_V3_EouClassifierOptions: @unchecked Sendable {}
extension Speechkit_Stt_V3_EouClassifierOptions.OneOf_Classifier: @unchecked Sendable {}
extension Speechkit_Stt_V3_RawAudio: @unchecked Sendable {}
extension Speechkit_Stt_V3_RawAudio.AudioEncoding: @unchecked Sendable {}
extension Speechkit_Stt_V3_ContainerAudio: @unchecked Sendable {}
extension Speechkit_Stt_V3_ContainerAudio.ContainerAudioType: @unchecked Sendable {}
extension Speechkit_Stt_V3_AudioFormatOptions: @unchecked Sendable {}
extension Speechkit_Stt_V3_AudioFormatOptions.OneOf_AudioFormat: @unchecked Sendable {}
extension Speechkit_Stt_V3_LanguageRestrictionOptions: @unchecked Sendable {}
extension Speechkit_Stt_V3_LanguageRestrictionOptions.LanguageRestrictionType: @unchecked Sendable {}
extension Speechkit_Stt_V3_RecognitionModelOptions: @unchecked Sendable {}
extension Speechkit_Stt_V3_RecognitionModelOptions.AudioProcessingType: @unchecked Sendable {}
extension Speechkit_Stt_V3_StreamingOptions: @unchecked Sendable {}
extension Speechkit_Stt_V3_AudioChunk: @unchecked Sendable {}
extension Speechkit_Stt_V3_SilenceChunk: @unchecked Sendable {}
extension Speechkit_Stt_V3_Eou: @unchecked Sendable {}
extension Speechkit_Stt_V3_StreamingRequest: @unchecked Sendable {}
extension Speechkit_Stt_V3_StreamingRequest.OneOf_Event: @unchecked Sendable {}
extension Speechkit_Stt_V3_Word: @unchecked Sendable {}
extension Speechkit_Stt_V3_Alternative: @unchecked Sendable {}
extension Speechkit_Stt_V3_EouUpdate: @unchecked Sendable {}
extension Speechkit_Stt_V3_AlternativeUpdate: @unchecked Sendable {}
extension Speechkit_Stt_V3_AudioCursors: @unchecked Sendable {}
extension Speechkit_Stt_V3_FinalRefinement: @unchecked Sendable {}
extension Speechkit_Stt_V3_FinalRefinement.OneOf_Type: @unchecked Sendable {}
extension Speechkit_Stt_V3_StatusCode: @unchecked Sendable {}
extension Speechkit_Stt_V3_SessionUuid: @unchecked Sendable {}
extension Speechkit_Stt_V3_StreamingResponse: @unchecked Sendable {}
extension Speechkit_Stt_V3_StreamingResponse.OneOf_Event: @unchecked Sendable {}
#endif  // swift(>=5.5) && canImport(_Concurrency)

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "speechkit.stt.v3"

extension Speechkit_Stt_V3_CodeType: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "CODE_TYPE_UNSPECIFIED"),
    1: .same(proto: "WORKING"),
    2: .same(proto: "WARNING"),
    3: .same(proto: "CLOSED"),
  ]
}

extension Speechkit_Stt_V3_TextNormalizationOptions: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".TextNormalizationOptions"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "text_normalization"),
    2: .standard(proto: "profanity_filter"),
    3: .standard(proto: "literature_text"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.textNormalization) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.profanityFilter) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.literatureText) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.textNormalization != .unspecified {
      try visitor.visitSingularEnumField(value: self.textNormalization, fieldNumber: 1)
    }
    if self.profanityFilter != false {
      try visitor.visitSingularBoolField(value: self.profanityFilter, fieldNumber: 2)
    }
    if self.literatureText != false {
      try visitor.visitSingularBoolField(value: self.literatureText, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_TextNormalizationOptions, rhs: Speechkit_Stt_V3_TextNormalizationOptions) -> Bool {
    if lhs.textNormalization != rhs.textNormalization {return false}
    if lhs.profanityFilter != rhs.profanityFilter {return false}
    if lhs.literatureText != rhs.literatureText {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_TextNormalizationOptions.TextNormalization: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "TEXT_NORMALIZATION_UNSPECIFIED"),
    1: .same(proto: "TEXT_NORMALIZATION_ENABLED"),
    2: .same(proto: "TEXT_NORMALIZATION_DISABLED"),
  ]
}

extension Speechkit_Stt_V3_DefaultEouClassifier: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".DefaultEouClassifier"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "type"),
    2: .standard(proto: "max_pause_between_words_hint_ms"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.type) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.maxPauseBetweenWordsHintMs) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.type != .unspecified {
      try visitor.visitSingularEnumField(value: self.type, fieldNumber: 1)
    }
    if self.maxPauseBetweenWordsHintMs != 0 {
      try visitor.visitSingularInt64Field(value: self.maxPauseBetweenWordsHintMs, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_DefaultEouClassifier, rhs: Speechkit_Stt_V3_DefaultEouClassifier) -> Bool {
    if lhs.type != rhs.type {return false}
    if lhs.maxPauseBetweenWordsHintMs != rhs.maxPauseBetweenWordsHintMs {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_DefaultEouClassifier.EouSensitivity: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "EOU_SENSITIVITY_UNSPECIFIED"),
    1: .same(proto: "DEFAULT"),
    2: .same(proto: "HIGH"),
  ]
}

extension Speechkit_Stt_V3_ExternalEouClassifier: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".ExternalEouClassifier"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let _ = try decoder.nextFieldNumber() {
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_ExternalEouClassifier, rhs: Speechkit_Stt_V3_ExternalEouClassifier) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_EouClassifierOptions: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".EouClassifierOptions"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "default_classifier"),
    2: .standard(proto: "external_classifier"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Speechkit_Stt_V3_DefaultEouClassifier?
        var hadOneofValue = false
        if let current = self.classifier {
          hadOneofValue = true
          if case .defaultClassifier(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.classifier = .defaultClassifier(v)
        }
      }()
      case 2: try {
        var v: Speechkit_Stt_V3_ExternalEouClassifier?
        var hadOneofValue = false
        if let current = self.classifier {
          hadOneofValue = true
          if case .externalClassifier(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.classifier = .externalClassifier(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.classifier {
    case .defaultClassifier?: try {
      guard case .defaultClassifier(let v)? = self.classifier else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .externalClassifier?: try {
      guard case .externalClassifier(let v)? = self.classifier else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_EouClassifierOptions, rhs: Speechkit_Stt_V3_EouClassifierOptions) -> Bool {
    if lhs.classifier != rhs.classifier {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_RawAudio: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".RawAudio"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "audio_encoding"),
    2: .standard(proto: "sample_rate_hertz"),
    3: .standard(proto: "audio_channel_count"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.audioEncoding) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.sampleRateHertz) }()
      case 3: try { try decoder.decodeSingularInt64Field(value: &self.audioChannelCount) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.audioEncoding != .unspecified {
      try visitor.visitSingularEnumField(value: self.audioEncoding, fieldNumber: 1)
    }
    if self.sampleRateHertz != 0 {
      try visitor.visitSingularInt64Field(value: self.sampleRateHertz, fieldNumber: 2)
    }
    if self.audioChannelCount != 0 {
      try visitor.visitSingularInt64Field(value: self.audioChannelCount, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_RawAudio, rhs: Speechkit_Stt_V3_RawAudio) -> Bool {
    if lhs.audioEncoding != rhs.audioEncoding {return false}
    if lhs.sampleRateHertz != rhs.sampleRateHertz {return false}
    if lhs.audioChannelCount != rhs.audioChannelCount {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_RawAudio.AudioEncoding: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "AUDIO_ENCODING_UNSPECIFIED"),
    1: .same(proto: "LINEAR16_PCM"),
  ]
}

extension Speechkit_Stt_V3_ContainerAudio: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".ContainerAudio"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "container_audio_type"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.containerAudioType) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.containerAudioType != .unspecified {
      try visitor.visitSingularEnumField(value: self.containerAudioType, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_ContainerAudio, rhs: Speechkit_Stt_V3_ContainerAudio) -> Bool {
    if lhs.containerAudioType != rhs.containerAudioType {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_ContainerAudio.ContainerAudioType: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "CONTAINER_AUDIO_TYPE_UNSPECIFIED"),
    1: .same(proto: "WAV"),
    2: .same(proto: "OGG_OPUS"),
    3: .same(proto: "MP3"),
  ]
}

extension Speechkit_Stt_V3_AudioFormatOptions: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".AudioFormatOptions"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "raw_audio"),
    2: .standard(proto: "container_audio"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Speechkit_Stt_V3_RawAudio?
        var hadOneofValue = false
        if let current = self.audioFormat {
          hadOneofValue = true
          if case .rawAudio(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.audioFormat = .rawAudio(v)
        }
      }()
      case 2: try {
        var v: Speechkit_Stt_V3_ContainerAudio?
        var hadOneofValue = false
        if let current = self.audioFormat {
          hadOneofValue = true
          if case .containerAudio(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.audioFormat = .containerAudio(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.audioFormat {
    case .rawAudio?: try {
      guard case .rawAudio(let v)? = self.audioFormat else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .containerAudio?: try {
      guard case .containerAudio(let v)? = self.audioFormat else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_AudioFormatOptions, rhs: Speechkit_Stt_V3_AudioFormatOptions) -> Bool {
    if lhs.audioFormat != rhs.audioFormat {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_LanguageRestrictionOptions: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".LanguageRestrictionOptions"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "restriction_type"),
    2: .standard(proto: "language_code"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.restrictionType) }()
      case 2: try { try decoder.decodeRepeatedStringField(value: &self.languageCode) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.restrictionType != .unspecified {
      try visitor.visitSingularEnumField(value: self.restrictionType, fieldNumber: 1)
    }
    if !self.languageCode.isEmpty {
      try visitor.visitRepeatedStringField(value: self.languageCode, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_LanguageRestrictionOptions, rhs: Speechkit_Stt_V3_LanguageRestrictionOptions) -> Bool {
    if lhs.restrictionType != rhs.restrictionType {return false}
    if lhs.languageCode != rhs.languageCode {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_LanguageRestrictionOptions.LanguageRestrictionType: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "LANGUAGE_RESTRICTION_TYPE_UNSPECIFIED"),
    1: .same(proto: "WHITELIST"),
    2: .same(proto: "BLACKLIST"),
  ]
}

extension Speechkit_Stt_V3_RecognitionModelOptions: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".RecognitionModelOptions"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "model"),
    2: .standard(proto: "audio_format"),
    3: .standard(proto: "text_normalization"),
    4: .standard(proto: "language_restriction"),
    5: .standard(proto: "audio_processing_type"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.model) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._audioFormat) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._textNormalization) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._languageRestriction) }()
      case 5: try { try decoder.decodeSingularEnumField(value: &self.audioProcessingType) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.model.isEmpty {
      try visitor.visitSingularStringField(value: self.model, fieldNumber: 1)
    }
    try { if let v = self._audioFormat {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._textNormalization {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._languageRestriction {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    if self.audioProcessingType != .unspecified {
      try visitor.visitSingularEnumField(value: self.audioProcessingType, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_RecognitionModelOptions, rhs: Speechkit_Stt_V3_RecognitionModelOptions) -> Bool {
    if lhs.model != rhs.model {return false}
    if lhs._audioFormat != rhs._audioFormat {return false}
    if lhs._textNormalization != rhs._textNormalization {return false}
    if lhs._languageRestriction != rhs._languageRestriction {return false}
    if lhs.audioProcessingType != rhs.audioProcessingType {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_RecognitionModelOptions.AudioProcessingType: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "AUDIO_PROCESSING_TYPE_UNSPECIFIED"),
    1: .same(proto: "REAL_TIME"),
    2: .same(proto: "FULL_DATA"),
  ]
}

extension Speechkit_Stt_V3_StreamingOptions: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".StreamingOptions"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "recognition_model"),
    2: .standard(proto: "eou_classifier"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._recognitionModel) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._eouClassifier) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._recognitionModel {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._eouClassifier {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_StreamingOptions, rhs: Speechkit_Stt_V3_StreamingOptions) -> Bool {
    if lhs._recognitionModel != rhs._recognitionModel {return false}
    if lhs._eouClassifier != rhs._eouClassifier {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_AudioChunk: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".AudioChunk"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "data"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBytesField(value: &self.data) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.data.isEmpty {
      try visitor.visitSingularBytesField(value: self.data, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_AudioChunk, rhs: Speechkit_Stt_V3_AudioChunk) -> Bool {
    if lhs.data != rhs.data {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_SilenceChunk: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".SilenceChunk"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "duration_ms"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.durationMs) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.durationMs != 0 {
      try visitor.visitSingularInt64Field(value: self.durationMs, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_SilenceChunk, rhs: Speechkit_Stt_V3_SilenceChunk) -> Bool {
    if lhs.durationMs != rhs.durationMs {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_Eou: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".Eou"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let _ = try decoder.nextFieldNumber() {
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_Eou, rhs: Speechkit_Stt_V3_Eou) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_StreamingRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".StreamingRequest"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "session_options"),
    2: .same(proto: "chunk"),
    3: .standard(proto: "silence_chunk"),
    4: .same(proto: "eou"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Speechkit_Stt_V3_StreamingOptions?
        var hadOneofValue = false
        if let current = self.event {
          hadOneofValue = true
          if case .sessionOptions(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.event = .sessionOptions(v)
        }
      }()
      case 2: try {
        var v: Speechkit_Stt_V3_AudioChunk?
        var hadOneofValue = false
        if let current = self.event {
          hadOneofValue = true
          if case .chunk(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.event = .chunk(v)
        }
      }()
      case 3: try {
        var v: Speechkit_Stt_V3_SilenceChunk?
        var hadOneofValue = false
        if let current = self.event {
          hadOneofValue = true
          if case .silenceChunk(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.event = .silenceChunk(v)
        }
      }()
      case 4: try {
        var v: Speechkit_Stt_V3_Eou?
        var hadOneofValue = false
        if let current = self.event {
          hadOneofValue = true
          if case .eou(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.event = .eou(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.event {
    case .sessionOptions?: try {
      guard case .sessionOptions(let v)? = self.event else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .chunk?: try {
      guard case .chunk(let v)? = self.event else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case .silenceChunk?: try {
      guard case .silenceChunk(let v)? = self.event else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case .eou?: try {
      guard case .eou(let v)? = self.event else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_StreamingRequest, rhs: Speechkit_Stt_V3_StreamingRequest) -> Bool {
    if lhs.event != rhs.event {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_Word: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".Word"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "text"),
    2: .standard(proto: "start_time_ms"),
    3: .standard(proto: "end_time_ms"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.text) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.startTimeMs) }()
      case 3: try { try decoder.decodeSingularInt64Field(value: &self.endTimeMs) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.text.isEmpty {
      try visitor.visitSingularStringField(value: self.text, fieldNumber: 1)
    }
    if self.startTimeMs != 0 {
      try visitor.visitSingularInt64Field(value: self.startTimeMs, fieldNumber: 2)
    }
    if self.endTimeMs != 0 {
      try visitor.visitSingularInt64Field(value: self.endTimeMs, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_Word, rhs: Speechkit_Stt_V3_Word) -> Bool {
    if lhs.text != rhs.text {return false}
    if lhs.startTimeMs != rhs.startTimeMs {return false}
    if lhs.endTimeMs != rhs.endTimeMs {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_Alternative: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".Alternative"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "words"),
    2: .same(proto: "text"),
    3: .standard(proto: "start_time_ms"),
    4: .standard(proto: "end_time_ms"),
    5: .same(proto: "confidence"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.words) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.text) }()
      case 3: try { try decoder.decodeSingularInt64Field(value: &self.startTimeMs) }()
      case 4: try { try decoder.decodeSingularInt64Field(value: &self.endTimeMs) }()
      case 5: try { try decoder.decodeSingularDoubleField(value: &self.confidence) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.words.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.words, fieldNumber: 1)
    }
    if !self.text.isEmpty {
      try visitor.visitSingularStringField(value: self.text, fieldNumber: 2)
    }
    if self.startTimeMs != 0 {
      try visitor.visitSingularInt64Field(value: self.startTimeMs, fieldNumber: 3)
    }
    if self.endTimeMs != 0 {
      try visitor.visitSingularInt64Field(value: self.endTimeMs, fieldNumber: 4)
    }
    if self.confidence != 0 {
      try visitor.visitSingularDoubleField(value: self.confidence, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_Alternative, rhs: Speechkit_Stt_V3_Alternative) -> Bool {
    if lhs.words != rhs.words {return false}
    if lhs.text != rhs.text {return false}
    if lhs.startTimeMs != rhs.startTimeMs {return false}
    if lhs.endTimeMs != rhs.endTimeMs {return false}
    if lhs.confidence != rhs.confidence {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_EouUpdate: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".EouUpdate"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    2: .standard(proto: "time_ms"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.timeMs) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.timeMs != 0 {
      try visitor.visitSingularInt64Field(value: self.timeMs, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_EouUpdate, rhs: Speechkit_Stt_V3_EouUpdate) -> Bool {
    if lhs.timeMs != rhs.timeMs {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_AlternativeUpdate: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".AlternativeUpdate"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "alternatives"),
    2: .standard(proto: "channel_tag"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.alternatives) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.channelTag) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.alternatives.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.alternatives, fieldNumber: 1)
    }
    if !self.channelTag.isEmpty {
      try visitor.visitSingularStringField(value: self.channelTag, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_AlternativeUpdate, rhs: Speechkit_Stt_V3_AlternativeUpdate) -> Bool {
    if lhs.alternatives != rhs.alternatives {return false}
    if lhs.channelTag != rhs.channelTag {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_AudioCursors: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".AudioCursors"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "received_data_ms"),
    2: .standard(proto: "reset_time_ms"),
    3: .standard(proto: "partial_time_ms"),
    4: .standard(proto: "final_time_ms"),
    5: .standard(proto: "final_index"),
    6: .standard(proto: "eou_time_ms"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.receivedDataMs) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.resetTimeMs) }()
      case 3: try { try decoder.decodeSingularInt64Field(value: &self.partialTimeMs) }()
      case 4: try { try decoder.decodeSingularInt64Field(value: &self.finalTimeMs) }()
      case 5: try { try decoder.decodeSingularInt64Field(value: &self.finalIndex) }()
      case 6: try { try decoder.decodeSingularInt64Field(value: &self.eouTimeMs) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.receivedDataMs != 0 {
      try visitor.visitSingularInt64Field(value: self.receivedDataMs, fieldNumber: 1)
    }
    if self.resetTimeMs != 0 {
      try visitor.visitSingularInt64Field(value: self.resetTimeMs, fieldNumber: 2)
    }
    if self.partialTimeMs != 0 {
      try visitor.visitSingularInt64Field(value: self.partialTimeMs, fieldNumber: 3)
    }
    if self.finalTimeMs != 0 {
      try visitor.visitSingularInt64Field(value: self.finalTimeMs, fieldNumber: 4)
    }
    if self.finalIndex != 0 {
      try visitor.visitSingularInt64Field(value: self.finalIndex, fieldNumber: 5)
    }
    if self.eouTimeMs != 0 {
      try visitor.visitSingularInt64Field(value: self.eouTimeMs, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_AudioCursors, rhs: Speechkit_Stt_V3_AudioCursors) -> Bool {
    if lhs.receivedDataMs != rhs.receivedDataMs {return false}
    if lhs.resetTimeMs != rhs.resetTimeMs {return false}
    if lhs.partialTimeMs != rhs.partialTimeMs {return false}
    if lhs.finalTimeMs != rhs.finalTimeMs {return false}
    if lhs.finalIndex != rhs.finalIndex {return false}
    if lhs.eouTimeMs != rhs.eouTimeMs {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_FinalRefinement: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".FinalRefinement"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "final_index"),
    2: .standard(proto: "normalized_text"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.finalIndex) }()
      case 2: try {
        var v: Speechkit_Stt_V3_AlternativeUpdate?
        var hadOneofValue = false
        if let current = self.type {
          hadOneofValue = true
          if case .normalizedText(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.type = .normalizedText(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.finalIndex != 0 {
      try visitor.visitSingularInt64Field(value: self.finalIndex, fieldNumber: 1)
    }
    try { if case .normalizedText(let v)? = self.type {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_FinalRefinement, rhs: Speechkit_Stt_V3_FinalRefinement) -> Bool {
    if lhs.finalIndex != rhs.finalIndex {return false}
    if lhs.type != rhs.type {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_StatusCode: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".StatusCode"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "code_type"),
    2: .same(proto: "message"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.codeType) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.message) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.codeType != .unspecified {
      try visitor.visitSingularEnumField(value: self.codeType, fieldNumber: 1)
    }
    if !self.message.isEmpty {
      try visitor.visitSingularStringField(value: self.message, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_StatusCode, rhs: Speechkit_Stt_V3_StatusCode) -> Bool {
    if lhs.codeType != rhs.codeType {return false}
    if lhs.message != rhs.message {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_SessionUuid: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".SessionUuid"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "uuid"),
    2: .standard(proto: "user_request_id"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.uuid) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.userRequestID) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.uuid.isEmpty {
      try visitor.visitSingularStringField(value: self.uuid, fieldNumber: 1)
    }
    if !self.userRequestID.isEmpty {
      try visitor.visitSingularStringField(value: self.userRequestID, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_SessionUuid, rhs: Speechkit_Stt_V3_SessionUuid) -> Bool {
    if lhs.uuid != rhs.uuid {return false}
    if lhs.userRequestID != rhs.userRequestID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Stt_V3_StreamingResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".StreamingResponse"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "session_uuid"),
    2: .standard(proto: "audio_cursors"),
    3: .standard(proto: "response_wall_time_ms"),
    4: .same(proto: "partial"),
    5: .same(proto: "final"),
    6: .standard(proto: "eou_update"),
    7: .standard(proto: "final_refinement"),
    8: .standard(proto: "status_code"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._sessionUuid) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._audioCursors) }()
      case 3: try { try decoder.decodeSingularInt64Field(value: &self.responseWallTimeMs) }()
      case 4: try {
        var v: Speechkit_Stt_V3_AlternativeUpdate?
        var hadOneofValue = false
        if let current = self.event {
          hadOneofValue = true
          if case .partial(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.event = .partial(v)
        }
      }()
      case 5: try {
        var v: Speechkit_Stt_V3_AlternativeUpdate?
        var hadOneofValue = false
        if let current = self.event {
          hadOneofValue = true
          if case .final(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.event = .final(v)
        }
      }()
      case 6: try {
        var v: Speechkit_Stt_V3_EouUpdate?
        var hadOneofValue = false
        if let current = self.event {
          hadOneofValue = true
          if case .eouUpdate(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.event = .eouUpdate(v)
        }
      }()
      case 7: try {
        var v: Speechkit_Stt_V3_FinalRefinement?
        var hadOneofValue = false
        if let current = self.event {
          hadOneofValue = true
          if case .finalRefinement(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.event = .finalRefinement(v)
        }
      }()
      case 8: try {
        var v: Speechkit_Stt_V3_StatusCode?
        var hadOneofValue = false
        if let current = self.event {
          hadOneofValue = true
          if case .statusCode(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.event = .statusCode(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._sessionUuid {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._audioCursors {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if self.responseWallTimeMs != 0 {
      try visitor.visitSingularInt64Field(value: self.responseWallTimeMs, fieldNumber: 3)
    }
    switch self.event {
    case .partial?: try {
      guard case .partial(let v)? = self.event else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }()
    case .final?: try {
      guard case .final(let v)? = self.event else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }()
    case .eouUpdate?: try {
      guard case .eouUpdate(let v)? = self.event else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }()
    case .finalRefinement?: try {
      guard case .finalRefinement(let v)? = self.event else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    }()
    case .statusCode?: try {
      guard case .statusCode(let v)? = self.event else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Stt_V3_StreamingResponse, rhs: Speechkit_Stt_V3_StreamingResponse) -> Bool {
    if lhs._sessionUuid != rhs._sessionUuid {return false}
    if lhs._audioCursors != rhs._audioCursors {return false}
    if lhs.responseWallTimeMs != rhs.responseWallTimeMs {return false}
    if lhs.event != rhs.event {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
