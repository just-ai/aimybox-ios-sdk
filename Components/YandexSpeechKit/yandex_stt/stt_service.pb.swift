// DO NOT EDIT.
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: yandex/cloud/ai/stt/v2/stt_service.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that your are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

public struct Yandex_Cloud_Ai_Stt_V2_LongRunningRecognitionRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var config: Yandex_Cloud_Ai_Stt_V2_RecognitionConfig {
    get {return _storage._config ?? Yandex_Cloud_Ai_Stt_V2_RecognitionConfig()}
    set {_uniqueStorage()._config = newValue}
  }
  /// Returns true if `config` has been explicitly set.
  public var hasConfig: Bool {return _storage._config != nil}
  /// Clears the value of `config`. Subsequent reads from it will return its default value.
  public mutating func clearConfig() {_uniqueStorage()._config = nil}

  public var audio: Yandex_Cloud_Ai_Stt_V2_RecognitionAudio {
    get {return _storage._audio ?? Yandex_Cloud_Ai_Stt_V2_RecognitionAudio()}
    set {_uniqueStorage()._audio = newValue}
  }
  /// Returns true if `audio` has been explicitly set.
  public var hasAudio: Bool {return _storage._audio != nil}
  /// Clears the value of `audio`. Subsequent reads from it will return its default value.
  public mutating func clearAudio() {_uniqueStorage()._audio = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

public struct Yandex_Cloud_Ai_Stt_V2_LongRunningRecognitionResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var chunks: [Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionResult] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Yandex_Cloud_Ai_Stt_V2_StreamingRecognitionRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var streamingRequest: OneOf_StreamingRequest? {
    get {return _storage._streamingRequest}
    set {_uniqueStorage()._streamingRequest = newValue}
  }

  public var config: Yandex_Cloud_Ai_Stt_V2_RecognitionConfig {
    get {
      if case .config(let v)? = _storage._streamingRequest {return v}
      return Yandex_Cloud_Ai_Stt_V2_RecognitionConfig()
    }
    set {_uniqueStorage()._streamingRequest = .config(newValue)}
  }

  public var audioContent: Data {
    get {
      if case .audioContent(let v)? = _storage._streamingRequest {return v}
      return SwiftProtobuf.Internal.emptyData
    }
    set {_uniqueStorage()._streamingRequest = .audioContent(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public enum OneOf_StreamingRequest: Equatable {
    case config(Yandex_Cloud_Ai_Stt_V2_RecognitionConfig)
    case audioContent(Data)

  #if !swift(>=4.1)
    public static func ==(lhs: Yandex_Cloud_Ai_Stt_V2_StreamingRecognitionRequest.OneOf_StreamingRequest, rhs: Yandex_Cloud_Ai_Stt_V2_StreamingRecognitionRequest.OneOf_StreamingRequest) -> Bool {
      switch (lhs, rhs) {
      case (.config(let l), .config(let r)): return l == r
      case (.audioContent(let l), .audioContent(let r)): return l == r
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

public struct Yandex_Cloud_Ai_Stt_V2_StreamingRecognitionResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var chunks: [Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionChunk] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Yandex_Cloud_Ai_Stt_V2_RecognitionAudio {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var audioSource: Yandex_Cloud_Ai_Stt_V2_RecognitionAudio.OneOf_AudioSource? = nil

  public var content: Data {
    get {
      if case .content(let v)? = audioSource {return v}
      return SwiftProtobuf.Internal.emptyData
    }
    set {audioSource = .content(newValue)}
  }

  public var uri: String {
    get {
      if case .uri(let v)? = audioSource {return v}
      return String()
    }
    set {audioSource = .uri(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public enum OneOf_AudioSource: Equatable {
    case content(Data)
    case uri(String)

  #if !swift(>=4.1)
    public static func ==(lhs: Yandex_Cloud_Ai_Stt_V2_RecognitionAudio.OneOf_AudioSource, rhs: Yandex_Cloud_Ai_Stt_V2_RecognitionAudio.OneOf_AudioSource) -> Bool {
      switch (lhs, rhs) {
      case (.content(let l), .content(let r)): return l == r
      case (.uri(let l), .uri(let r)): return l == r
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

public struct Yandex_Cloud_Ai_Stt_V2_RecognitionConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var specification: Yandex_Cloud_Ai_Stt_V2_RecognitionSpec {
    get {return _storage._specification ?? Yandex_Cloud_Ai_Stt_V2_RecognitionSpec()}
    set {_uniqueStorage()._specification = newValue}
  }
  /// Returns true if `specification` has been explicitly set.
  public var hasSpecification: Bool {return _storage._specification != nil}
  /// Clears the value of `specification`. Subsequent reads from it will return its default value.
  public mutating func clearSpecification() {_uniqueStorage()._specification = nil}

  public var folderID: String {
    get {return _storage._folderID}
    set {_uniqueStorage()._folderID = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

public struct Yandex_Cloud_Ai_Stt_V2_RecognitionSpec {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var audioEncoding: Yandex_Cloud_Ai_Stt_V2_RecognitionSpec.AudioEncoding = .unspecified

  /// 8000, 16000, 48000 only for pcm
  public var sampleRateHertz: Int64 = 0

  /// code in BCP-47
  public var languageCode: String = String()

  public var profanityFilter: Bool = false

  public var model: String = String()

  /// If set true, tentative hypotheses may be returned as they become available (final=false flag)
  /// If false or omitted, only final=true result(s) are returned.
  /// Makes sense only for StreamingRecognize requests.
  public var partialResults: Bool = false

  public var singleUtterance: Bool = false

  /// Used only for long running recognize.
  public var audioChannelCount: Int64 = 0

  /// This mark allows disable normalization text
  public var rawResults: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public enum AudioEncoding: SwiftProtobuf.Enum {
    public typealias RawValue = Int
    case unspecified // = 0

    /// 16-bit signed little-endian (Linear PCM)
    case linear16Pcm // = 1
    case oggOpus // = 2
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .linear16Pcm
      case 2: self = .oggOpus
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .linear16Pcm: return 1
      case .oggOpus: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}
}

#if swift(>=4.2)

extension Yandex_Cloud_Ai_Stt_V2_RecognitionSpec.AudioEncoding: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Yandex_Cloud_Ai_Stt_V2_RecognitionSpec.AudioEncoding] = [
    .unspecified,
    .linear16Pcm,
    .oggOpus,
  ]
}

#endif  // swift(>=4.2)

public struct Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionChunk {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var alternatives: [Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionAlternative] = []

  /// This flag shows that the received chunk contains a part of the recognized text that won't be changed.
  public var final: Bool = false

  /// This flag shows that the received chunk is the end of an utterance.
  public var endOfUtterance: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionResult {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var alternatives: [Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionAlternative] = []

  public var channelTag: Int64 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionAlternative {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var text: String = String()

  public var confidence: Float = 0

  public var words: [Yandex_Cloud_Ai_Stt_V2_WordInfo] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Yandex_Cloud_Ai_Stt_V2_WordInfo {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var startTime: SwiftProtobuf.Google_Protobuf_Duration {
    get {return _storage._startTime ?? SwiftProtobuf.Google_Protobuf_Duration()}
    set {_uniqueStorage()._startTime = newValue}
  }
  /// Returns true if `startTime` has been explicitly set.
  public var hasStartTime: Bool {return _storage._startTime != nil}
  /// Clears the value of `startTime`. Subsequent reads from it will return its default value.
  public mutating func clearStartTime() {_uniqueStorage()._startTime = nil}

  public var endTime: SwiftProtobuf.Google_Protobuf_Duration {
    get {return _storage._endTime ?? SwiftProtobuf.Google_Protobuf_Duration()}
    set {_uniqueStorage()._endTime = newValue}
  }
  /// Returns true if `endTime` has been explicitly set.
  public var hasEndTime: Bool {return _storage._endTime != nil}
  /// Clears the value of `endTime`. Subsequent reads from it will return its default value.
  public mutating func clearEndTime() {_uniqueStorage()._endTime = nil}

  public var word: String {
    get {return _storage._word}
    set {_uniqueStorage()._word = newValue}
  }

  public var confidence: Float {
    get {return _storage._confidence}
    set {_uniqueStorage()._confidence = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "yandex.cloud.ai.stt.v2"

extension Yandex_Cloud_Ai_Stt_V2_LongRunningRecognitionRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".LongRunningRecognitionRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .same(proto: "audio"),
  ]

  fileprivate class _StorageClass {
    var _config: Yandex_Cloud_Ai_Stt_V2_RecognitionConfig? = nil
    var _audio: Yandex_Cloud_Ai_Stt_V2_RecognitionAudio? = nil

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _config = source._config
      _audio = source._audio
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        switch fieldNumber {
        case 1: try decoder.decodeSingularMessageField(value: &_storage._config)
        case 2: try decoder.decodeSingularMessageField(value: &_storage._audio)
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if let v = _storage._config {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      }
      if let v = _storage._audio {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Yandex_Cloud_Ai_Stt_V2_LongRunningRecognitionRequest, rhs: Yandex_Cloud_Ai_Stt_V2_LongRunningRecognitionRequest) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._config != rhs_storage._config {return false}
        if _storage._audio != rhs_storage._audio {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Yandex_Cloud_Ai_Stt_V2_LongRunningRecognitionResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".LongRunningRecognitionResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "chunks"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      switch fieldNumber {
      case 1: try decoder.decodeRepeatedMessageField(value: &self.chunks)
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.chunks.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.chunks, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Yandex_Cloud_Ai_Stt_V2_LongRunningRecognitionResponse, rhs: Yandex_Cloud_Ai_Stt_V2_LongRunningRecognitionResponse) -> Bool {
    if lhs.chunks != rhs.chunks {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Yandex_Cloud_Ai_Stt_V2_StreamingRecognitionRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StreamingRecognitionRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .standard(proto: "audio_content"),
  ]

  fileprivate class _StorageClass {
    var _streamingRequest: Yandex_Cloud_Ai_Stt_V2_StreamingRecognitionRequest.OneOf_StreamingRequest?

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _streamingRequest = source._streamingRequest
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        switch fieldNumber {
        case 1:
          var v: Yandex_Cloud_Ai_Stt_V2_RecognitionConfig?
          if let current = _storage._streamingRequest {
            try decoder.handleConflictingOneOf()
            if case .config(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._streamingRequest = .config(v)}
        case 2:
          if _storage._streamingRequest != nil {try decoder.handleConflictingOneOf()}
          var v: Data?
          try decoder.decodeSingularBytesField(value: &v)
          if let v = v {_storage._streamingRequest = .audioContent(v)}
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      switch _storage._streamingRequest {
      case .config(let v)?:
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      case .audioContent(let v)?:
        try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
      case nil: break
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Yandex_Cloud_Ai_Stt_V2_StreamingRecognitionRequest, rhs: Yandex_Cloud_Ai_Stt_V2_StreamingRecognitionRequest) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._streamingRequest != rhs_storage._streamingRequest {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Yandex_Cloud_Ai_Stt_V2_StreamingRecognitionResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StreamingRecognitionResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "chunks"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      switch fieldNumber {
      case 1: try decoder.decodeRepeatedMessageField(value: &self.chunks)
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.chunks.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.chunks, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Yandex_Cloud_Ai_Stt_V2_StreamingRecognitionResponse, rhs: Yandex_Cloud_Ai_Stt_V2_StreamingRecognitionResponse) -> Bool {
    if lhs.chunks != rhs.chunks {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Yandex_Cloud_Ai_Stt_V2_RecognitionAudio: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".RecognitionAudio"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "content"),
    2: .same(proto: "uri"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      switch fieldNumber {
      case 1:
        if self.audioSource != nil {try decoder.handleConflictingOneOf()}
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {self.audioSource = .content(v)}
      case 2:
        if self.audioSource != nil {try decoder.handleConflictingOneOf()}
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {self.audioSource = .uri(v)}
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    switch self.audioSource {
    case .content(let v)?:
      try visitor.visitSingularBytesField(value: v, fieldNumber: 1)
    case .uri(let v)?:
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Yandex_Cloud_Ai_Stt_V2_RecognitionAudio, rhs: Yandex_Cloud_Ai_Stt_V2_RecognitionAudio) -> Bool {
    if lhs.audioSource != rhs.audioSource {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Yandex_Cloud_Ai_Stt_V2_RecognitionConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".RecognitionConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "specification"),
    2: .standard(proto: "folder_id"),
  ]

  fileprivate class _StorageClass {
    var _specification: Yandex_Cloud_Ai_Stt_V2_RecognitionSpec? = nil
    var _folderID: String = String()

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _specification = source._specification
      _folderID = source._folderID
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        switch fieldNumber {
        case 1: try decoder.decodeSingularMessageField(value: &_storage._specification)
        case 2: try decoder.decodeSingularStringField(value: &_storage._folderID)
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if let v = _storage._specification {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      }
      if !_storage._folderID.isEmpty {
        try visitor.visitSingularStringField(value: _storage._folderID, fieldNumber: 2)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Yandex_Cloud_Ai_Stt_V2_RecognitionConfig, rhs: Yandex_Cloud_Ai_Stt_V2_RecognitionConfig) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._specification != rhs_storage._specification {return false}
        if _storage._folderID != rhs_storage._folderID {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Yandex_Cloud_Ai_Stt_V2_RecognitionSpec: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".RecognitionSpec"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "audio_encoding"),
    2: .standard(proto: "sample_rate_hertz"),
    3: .standard(proto: "language_code"),
    4: .standard(proto: "profanity_filter"),
    5: .same(proto: "model"),
    7: .standard(proto: "partial_results"),
    8: .standard(proto: "single_utterance"),
    9: .standard(proto: "audio_channel_count"),
    10: .standard(proto: "raw_results"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      switch fieldNumber {
      case 1: try decoder.decodeSingularEnumField(value: &self.audioEncoding)
      case 2: try decoder.decodeSingularInt64Field(value: &self.sampleRateHertz)
      case 3: try decoder.decodeSingularStringField(value: &self.languageCode)
      case 4: try decoder.decodeSingularBoolField(value: &self.profanityFilter)
      case 5: try decoder.decodeSingularStringField(value: &self.model)
      case 7: try decoder.decodeSingularBoolField(value: &self.partialResults)
      case 8: try decoder.decodeSingularBoolField(value: &self.singleUtterance)
      case 9: try decoder.decodeSingularInt64Field(value: &self.audioChannelCount)
      case 10: try decoder.decodeSingularBoolField(value: &self.rawResults)
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.audioEncoding != .unspecified {
      try visitor.visitSingularEnumField(value: self.audioEncoding, fieldNumber: 1)
    }
    if self.sampleRateHertz != 0 {
      try visitor.visitSingularInt64Field(value: self.sampleRateHertz, fieldNumber: 2)
    }
    if !self.languageCode.isEmpty {
      try visitor.visitSingularStringField(value: self.languageCode, fieldNumber: 3)
    }
    if self.profanityFilter != false {
      try visitor.visitSingularBoolField(value: self.profanityFilter, fieldNumber: 4)
    }
    if !self.model.isEmpty {
      try visitor.visitSingularStringField(value: self.model, fieldNumber: 5)
    }
    if self.partialResults != false {
      try visitor.visitSingularBoolField(value: self.partialResults, fieldNumber: 7)
    }
    if self.singleUtterance != false {
      try visitor.visitSingularBoolField(value: self.singleUtterance, fieldNumber: 8)
    }
    if self.audioChannelCount != 0 {
      try visitor.visitSingularInt64Field(value: self.audioChannelCount, fieldNumber: 9)
    }
    if self.rawResults != false {
      try visitor.visitSingularBoolField(value: self.rawResults, fieldNumber: 10)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Yandex_Cloud_Ai_Stt_V2_RecognitionSpec, rhs: Yandex_Cloud_Ai_Stt_V2_RecognitionSpec) -> Bool {
    if lhs.audioEncoding != rhs.audioEncoding {return false}
    if lhs.sampleRateHertz != rhs.sampleRateHertz {return false}
    if lhs.languageCode != rhs.languageCode {return false}
    if lhs.profanityFilter != rhs.profanityFilter {return false}
    if lhs.model != rhs.model {return false}
    if lhs.partialResults != rhs.partialResults {return false}
    if lhs.singleUtterance != rhs.singleUtterance {return false}
    if lhs.audioChannelCount != rhs.audioChannelCount {return false}
    if lhs.rawResults != rhs.rawResults {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Yandex_Cloud_Ai_Stt_V2_RecognitionSpec.AudioEncoding: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "AUDIO_ENCODING_UNSPECIFIED"),
    1: .same(proto: "LINEAR16_PCM"),
    2: .same(proto: "OGG_OPUS"),
  ]
}

extension Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionChunk: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SpeechRecognitionChunk"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "alternatives"),
    2: .same(proto: "final"),
    3: .standard(proto: "end_of_utterance"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      switch fieldNumber {
      case 1: try decoder.decodeRepeatedMessageField(value: &self.alternatives)
      case 2: try decoder.decodeSingularBoolField(value: &self.final)
      case 3: try decoder.decodeSingularBoolField(value: &self.endOfUtterance)
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.alternatives.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.alternatives, fieldNumber: 1)
    }
    if self.final != false {
      try visitor.visitSingularBoolField(value: self.final, fieldNumber: 2)
    }
    if self.endOfUtterance != false {
      try visitor.visitSingularBoolField(value: self.endOfUtterance, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionChunk, rhs: Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionChunk) -> Bool {
    if lhs.alternatives != rhs.alternatives {return false}
    if lhs.final != rhs.final {return false}
    if lhs.endOfUtterance != rhs.endOfUtterance {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SpeechRecognitionResult"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "alternatives"),
    2: .standard(proto: "channel_tag"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      switch fieldNumber {
      case 1: try decoder.decodeRepeatedMessageField(value: &self.alternatives)
      case 2: try decoder.decodeSingularInt64Field(value: &self.channelTag)
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.alternatives.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.alternatives, fieldNumber: 1)
    }
    if self.channelTag != 0 {
      try visitor.visitSingularInt64Field(value: self.channelTag, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionResult, rhs: Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionResult) -> Bool {
    if lhs.alternatives != rhs.alternatives {return false}
    if lhs.channelTag != rhs.channelTag {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionAlternative: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SpeechRecognitionAlternative"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "text"),
    2: .same(proto: "confidence"),
    3: .same(proto: "words"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      switch fieldNumber {
      case 1: try decoder.decodeSingularStringField(value: &self.text)
      case 2: try decoder.decodeSingularFloatField(value: &self.confidence)
      case 3: try decoder.decodeRepeatedMessageField(value: &self.words)
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.text.isEmpty {
      try visitor.visitSingularStringField(value: self.text, fieldNumber: 1)
    }
    if self.confidence != 0 {
      try visitor.visitSingularFloatField(value: self.confidence, fieldNumber: 2)
    }
    if !self.words.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.words, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionAlternative, rhs: Yandex_Cloud_Ai_Stt_V2_SpeechRecognitionAlternative) -> Bool {
    if lhs.text != rhs.text {return false}
    if lhs.confidence != rhs.confidence {return false}
    if lhs.words != rhs.words {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Yandex_Cloud_Ai_Stt_V2_WordInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".WordInfo"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "start_time"),
    2: .standard(proto: "end_time"),
    3: .same(proto: "word"),
    4: .same(proto: "confidence"),
  ]

  fileprivate class _StorageClass {
    var _startTime: SwiftProtobuf.Google_Protobuf_Duration? = nil
    var _endTime: SwiftProtobuf.Google_Protobuf_Duration? = nil
    var _word: String = String()
    var _confidence: Float = 0

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _startTime = source._startTime
      _endTime = source._endTime
      _word = source._word
      _confidence = source._confidence
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        switch fieldNumber {
        case 1: try decoder.decodeSingularMessageField(value: &_storage._startTime)
        case 2: try decoder.decodeSingularMessageField(value: &_storage._endTime)
        case 3: try decoder.decodeSingularStringField(value: &_storage._word)
        case 4: try decoder.decodeSingularFloatField(value: &_storage._confidence)
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if let v = _storage._startTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      }
      if let v = _storage._endTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }
      if !_storage._word.isEmpty {
        try visitor.visitSingularStringField(value: _storage._word, fieldNumber: 3)
      }
      if _storage._confidence != 0 {
        try visitor.visitSingularFloatField(value: _storage._confidence, fieldNumber: 4)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Yandex_Cloud_Ai_Stt_V2_WordInfo, rhs: Yandex_Cloud_Ai_Stt_V2_WordInfo) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._startTime != rhs_storage._startTime {return false}
        if _storage._endTime != rhs_storage._endTime {return false}
        if _storage._word != rhs_storage._word {return false}
        if _storage._confidence != rhs_storage._confidence {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
