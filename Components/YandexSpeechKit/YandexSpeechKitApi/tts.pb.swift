// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: yandex/cloud/ai/tts/v3/tts.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

struct Speechkit_Tts_V3_AudioContent {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The audio source to read the data from.
  var audioSource: Speechkit_Tts_V3_AudioContent.OneOf_AudioSource? = nil

  /// Bytes with audio data.
  var content: Data {
    get {
      if case .content(let v)? = audioSource {return v}
      return Data()
    }
    set {audioSource = .content(newValue)}
  }

  /// Description of the audio format.
  var audioSpec: Speechkit_Tts_V3_AudioFormatOptions {
    get {return _audioSpec ?? Speechkit_Tts_V3_AudioFormatOptions()}
    set {_audioSpec = newValue}
  }
  /// Returns true if `audioSpec` has been explicitly set.
  var hasAudioSpec: Bool {return self._audioSpec != nil}
  /// Clears the value of `audioSpec`. Subsequent reads from it will return its default value.
  mutating func clearAudioSpec() {self._audioSpec = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The audio source to read the data from.
  enum OneOf_AudioSource: Equatable {
    /// Bytes with audio data.
    case content(Data)

  #if !swift(>=4.1)
    static func ==(lhs: Speechkit_Tts_V3_AudioContent.OneOf_AudioSource, rhs: Speechkit_Tts_V3_AudioContent.OneOf_AudioSource) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.content, .content): return {
        guard case .content(let l) = lhs, case .content(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      }
    }
  #endif
  }

  init() {}

  fileprivate var _audioSpec: Speechkit_Tts_V3_AudioFormatOptions? = nil
}

struct Speechkit_Tts_V3_AudioFormatOptions {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var audioFormat: Speechkit_Tts_V3_AudioFormatOptions.OneOf_AudioFormat? = nil

  /// The audio format specified in request parameters.
  var rawAudio: Speechkit_Tts_V3_RawAudio {
    get {
      if case .rawAudio(let v)? = audioFormat {return v}
      return Speechkit_Tts_V3_RawAudio()
    }
    set {audioFormat = .rawAudio(newValue)}
  }

  /// The audio format specified inside the container metadata.
  var containerAudio: Speechkit_Tts_V3_ContainerAudio {
    get {
      if case .containerAudio(let v)? = audioFormat {return v}
      return Speechkit_Tts_V3_ContainerAudio()
    }
    set {audioFormat = .containerAudio(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum OneOf_AudioFormat: Equatable {
    /// The audio format specified in request parameters.
    case rawAudio(Speechkit_Tts_V3_RawAudio)
    /// The audio format specified inside the container metadata.
    case containerAudio(Speechkit_Tts_V3_ContainerAudio)

  #if !swift(>=4.1)
    static func ==(lhs: Speechkit_Tts_V3_AudioFormatOptions.OneOf_AudioFormat, rhs: Speechkit_Tts_V3_AudioFormatOptions.OneOf_AudioFormat) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.rawAudio, .rawAudio): return {
        guard case .rawAudio(let l) = lhs, case .rawAudio(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.containerAudio, .containerAudio): return {
        guard case .containerAudio(let l) = lhs, case .containerAudio(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  init() {}
}

struct Speechkit_Tts_V3_RawAudio {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Encoding type.
  var audioEncoding: Speechkit_Tts_V3_RawAudio.AudioEncoding = .unspecified

  /// Sampling frequency of the signal.
  var sampleRateHertz: Int64 = 0

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum AudioEncoding: SwiftProtobuf.Enum {
    typealias RawValue = Int
    case unspecified // = 0

    /// Audio bit depth 16-bit signed little-endian (Linear PCM).
    case linear16Pcm // = 1
    case UNRECOGNIZED(Int)

    init() {
      self = .unspecified
    }

    init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .linear16Pcm
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .linear16Pcm: return 1
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  init() {}
}

#if swift(>=4.2)

extension Speechkit_Tts_V3_RawAudio.AudioEncoding: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Speechkit_Tts_V3_RawAudio.AudioEncoding] = [
    .unspecified,
    .linear16Pcm,
  ]
}

#endif  // swift(>=4.2)

struct Speechkit_Tts_V3_ContainerAudio {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var containerAudioType: Speechkit_Tts_V3_ContainerAudio.ContainerAudioType = .unspecified

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum ContainerAudioType: SwiftProtobuf.Enum {
    typealias RawValue = Int
    case unspecified // = 0

    /// Audio bit depth 16-bit signed little-endian (Linear PCM).
    case wav // = 1
    case oggOpus // = 2
    case mp3 // = 3
    case UNRECOGNIZED(Int)

    init() {
      self = .unspecified
    }

    init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .wav
      case 2: self = .oggOpus
      case 3: self = .mp3
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .wav: return 1
      case .oggOpus: return 2
      case .mp3: return 3
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  init() {}
}

#if swift(>=4.2)

extension Speechkit_Tts_V3_ContainerAudio.ContainerAudioType: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Speechkit_Tts_V3_ContainerAudio.ContainerAudioType] = [
    .unspecified,
    .wav,
    .oggOpus,
    .mp3,
  ]
}

#endif  // swift(>=4.2)

struct Speechkit_Tts_V3_TextVariable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The name of the variable.
  var variableName: String = String()

  /// The text of the variable.
  var variableValue: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

struct Speechkit_Tts_V3_AudioVariable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The name of the variable.
  var variableName: String = String()

  /// Start time of the variable in milliseconds.
  var variableStartMs: Int64 = 0

  /// Length of the variable in milliseconds.
  var variableLengthMs: Int64 = 0

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

struct Speechkit_Tts_V3_UtteranceSynthesisResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Part of synthesized audio.
  var audioChunk: Speechkit_Tts_V3_AudioChunk {
    get {return _audioChunk ?? Speechkit_Tts_V3_AudioChunk()}
    set {_audioChunk = newValue}
  }
  /// Returns true if `audioChunk` has been explicitly set.
  var hasAudioChunk: Bool {return self._audioChunk != nil}
  /// Clears the value of `audioChunk`. Subsequent reads from it will return its default value.
  mutating func clearAudioChunk() {self._audioChunk = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _audioChunk: Speechkit_Tts_V3_AudioChunk? = nil
}

struct Speechkit_Tts_V3_AudioTemplate {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Audio file.
  var audio: Speechkit_Tts_V3_AudioContent {
    get {return _audio ?? Speechkit_Tts_V3_AudioContent()}
    set {_audio = newValue}
  }
  /// Returns true if `audio` has been explicitly set.
  var hasAudio: Bool {return self._audio != nil}
  /// Clears the value of `audio`. Subsequent reads from it will return its default value.
  mutating func clearAudio() {self._audio = nil}

  /// Template and description of its variables.
  var textTemplate: Speechkit_Tts_V3_TextTemplate {
    get {return _textTemplate ?? Speechkit_Tts_V3_TextTemplate()}
    set {_textTemplate = newValue}
  }
  /// Returns true if `textTemplate` has been explicitly set.
  var hasTextTemplate: Bool {return self._textTemplate != nil}
  /// Clears the value of `textTemplate`. Subsequent reads from it will return its default value.
  mutating func clearTextTemplate() {self._textTemplate = nil}

  /// Describing variables in audio.
  var variables: [Speechkit_Tts_V3_AudioVariable] = []

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _audio: Speechkit_Tts_V3_AudioContent? = nil
  fileprivate var _textTemplate: Speechkit_Tts_V3_TextTemplate? = nil
}

struct Speechkit_Tts_V3_AudioChunk {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Sequence of bytes of the synthesized audio in format specified in output_audio_spec.
  var data: Data = Data()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

struct Speechkit_Tts_V3_TextTemplate {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Template text.
  ///
  /// Sample:`The {animal} goes to the {place}.`
  var textTemplate: String = String()

  /// Defining variables in template text.
  ///
  /// Sample: `{animal: cat, place: forest}`
  var variables: [Speechkit_Tts_V3_TextVariable] = []

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

struct Speechkit_Tts_V3_Hints {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The hint for TTS engine to specify synthesised audio characteristics. 
  var hint: Speechkit_Tts_V3_Hints.OneOf_Hint? = nil

  /// Name of speaker to use.
  var voice: String {
    get {
      if case .voice(let v)? = hint {return v}
      return String()
    }
    set {hint = .voice(newValue)}
  }

  /// Template for synthesizing.
  var audioTemplate: Speechkit_Tts_V3_AudioTemplate {
    get {
      if case .audioTemplate(let v)? = hint {return v}
      return Speechkit_Tts_V3_AudioTemplate()
    }
    set {hint = .audioTemplate(newValue)}
  }

  /// hint to change speed
  var speed: Double {
    get {
      if case .speed(let v)? = hint {return v}
      return 0
    }
    set {hint = .speed(newValue)}
  }

  /// hint to regulate volume. For LOUDNESS_NORMALIZATION_TYPE_UNSPECIFIED normalization will use MAX_PEAK, if volume in (0, 1], LUFS if volume in [-145, 0).
  var volume: Double {
    get {
      if case .volume(let v)? = hint {return v}
      return 0
    }
    set {hint = .volume(newValue)}
  }

  var role: String {
    get {
      if case .role(let v)? = hint {return v}
      return String()
    }
    set {hint = .role(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The hint for TTS engine to specify synthesised audio characteristics. 
  enum OneOf_Hint: Equatable {
    /// Name of speaker to use.
    case voice(String)
    /// Template for synthesizing.
    case audioTemplate(Speechkit_Tts_V3_AudioTemplate)
    /// hint to change speed
    case speed(Double)
    /// hint to regulate volume. For LOUDNESS_NORMALIZATION_TYPE_UNSPECIFIED normalization will use MAX_PEAK, if volume in (0, 1], LUFS if volume in [-145, 0).
    case volume(Double)
    case role(String)

  #if !swift(>=4.1)
    static func ==(lhs: Speechkit_Tts_V3_Hints.OneOf_Hint, rhs: Speechkit_Tts_V3_Hints.OneOf_Hint) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.voice, .voice): return {
        guard case .voice(let l) = lhs, case .voice(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.audioTemplate, .audioTemplate): return {
        guard case .audioTemplate(let l) = lhs, case .audioTemplate(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.speed, .speed): return {
        guard case .speed(let l) = lhs, case .speed(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.volume, .volume): return {
        guard case .volume(let l) = lhs, case .volume(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.role, .role): return {
        guard case .role(let l) = lhs, case .role(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  init() {}
}

struct Speechkit_Tts_V3_UtteranceSynthesisRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The name of the model.
  /// Specifies basic synthesis functionality. Currently should be empty. Do not use it
  var model: String = String()

  /// Text to synthesis, one of text synthesis markups.
  var utterance: Speechkit_Tts_V3_UtteranceSynthesisRequest.OneOf_Utterance? = nil

  /// Raw text (e.g. "Hello, Alice").
  var text: String {
    get {
      if case .text(let v)? = utterance {return v}
      return String()
    }
    set {utterance = .text(newValue)}
  }

  /// Text template instance, e.g. `{"Hello, {username}" with username="Alice"}`.
  var textTemplate: Speechkit_Tts_V3_TextTemplate {
    get {
      if case .textTemplate(let v)? = utterance {return v}
      return Speechkit_Tts_V3_TextTemplate()
    }
    set {utterance = .textTemplate(newValue)}
  }

  /// Optional hints for synthesis.
  var hints: [Speechkit_Tts_V3_Hints] = []

  /// Optional. Default: 22050 Hz, linear 16-bit signed little-endian PCM, with WAV header
  var outputAudioSpec: Speechkit_Tts_V3_AudioFormatOptions {
    get {return _outputAudioSpec ?? Speechkit_Tts_V3_AudioFormatOptions()}
    set {_outputAudioSpec = newValue}
  }
  /// Returns true if `outputAudioSpec` has been explicitly set.
  var hasOutputAudioSpec: Bool {return self._outputAudioSpec != nil}
  /// Clears the value of `outputAudioSpec`. Subsequent reads from it will return its default value.
  mutating func clearOutputAudioSpec() {self._outputAudioSpec = nil}

  /// Optional. Default: LUFS, type of loudness normalization, default value -19.
  var loudnessNormalizationType: Speechkit_Tts_V3_UtteranceSynthesisRequest.LoudnessNormalizationType = .unspecified

  /// Optional. Automatically split long text to several utterances and bill accordingly. Some degradation in service quality is possible.
  var unsafeMode: Bool = false

  var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Text to synthesis, one of text synthesis markups.
  enum OneOf_Utterance: Equatable {
    /// Raw text (e.g. "Hello, Alice").
    case text(String)
    /// Text template instance, e.g. `{"Hello, {username}" with username="Alice"}`.
    case textTemplate(Speechkit_Tts_V3_TextTemplate)

  #if !swift(>=4.1)
    static func ==(lhs: Speechkit_Tts_V3_UtteranceSynthesisRequest.OneOf_Utterance, rhs: Speechkit_Tts_V3_UtteranceSynthesisRequest.OneOf_Utterance) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.text, .text): return {
        guard case .text(let l) = lhs, case .text(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.textTemplate, .textTemplate): return {
        guard case .textTemplate(let l) = lhs, case .textTemplate(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  /// Normalization type
  enum LoudnessNormalizationType: SwiftProtobuf.Enum {
    typealias RawValue = Int
    case unspecified // = 0
    case maxPeak // = 1
    case lufs // = 2
    case UNRECOGNIZED(Int)

    init() {
      self = .unspecified
    }

    init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .maxPeak
      case 2: self = .lufs
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .maxPeak: return 1
      case .lufs: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  init() {}

  fileprivate var _outputAudioSpec: Speechkit_Tts_V3_AudioFormatOptions? = nil
}

#if swift(>=4.2)

extension Speechkit_Tts_V3_UtteranceSynthesisRequest.LoudnessNormalizationType: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Speechkit_Tts_V3_UtteranceSynthesisRequest.LoudnessNormalizationType] = [
    .unspecified,
    .maxPeak,
    .lufs,
  ]
}

#endif  // swift(>=4.2)

#if swift(>=5.5) && canImport(_Concurrency)
extension Speechkit_Tts_V3_AudioContent: @unchecked Sendable {}
extension Speechkit_Tts_V3_AudioContent.OneOf_AudioSource: @unchecked Sendable {}
extension Speechkit_Tts_V3_AudioFormatOptions: @unchecked Sendable {}
extension Speechkit_Tts_V3_AudioFormatOptions.OneOf_AudioFormat: @unchecked Sendable {}
extension Speechkit_Tts_V3_RawAudio: @unchecked Sendable {}
extension Speechkit_Tts_V3_RawAudio.AudioEncoding: @unchecked Sendable {}
extension Speechkit_Tts_V3_ContainerAudio: @unchecked Sendable {}
extension Speechkit_Tts_V3_ContainerAudio.ContainerAudioType: @unchecked Sendable {}
extension Speechkit_Tts_V3_TextVariable: @unchecked Sendable {}
extension Speechkit_Tts_V3_AudioVariable: @unchecked Sendable {}
extension Speechkit_Tts_V3_UtteranceSynthesisResponse: @unchecked Sendable {}
extension Speechkit_Tts_V3_AudioTemplate: @unchecked Sendable {}
extension Speechkit_Tts_V3_AudioChunk: @unchecked Sendable {}
extension Speechkit_Tts_V3_TextTemplate: @unchecked Sendable {}
extension Speechkit_Tts_V3_Hints: @unchecked Sendable {}
extension Speechkit_Tts_V3_Hints.OneOf_Hint: @unchecked Sendable {}
extension Speechkit_Tts_V3_UtteranceSynthesisRequest: @unchecked Sendable {}
extension Speechkit_Tts_V3_UtteranceSynthesisRequest.OneOf_Utterance: @unchecked Sendable {}
extension Speechkit_Tts_V3_UtteranceSynthesisRequest.LoudnessNormalizationType: @unchecked Sendable {}
#endif  // swift(>=5.5) && canImport(_Concurrency)

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "speechkit.tts.v3"

extension Speechkit_Tts_V3_AudioContent: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".AudioContent"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "content"),
    2: .standard(proto: "audio_spec"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.audioSource != nil {try decoder.handleConflictingOneOf()}
          self.audioSource = .content(v)
        }
      }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._audioSpec) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if case .content(let v)? = self.audioSource {
      try visitor.visitSingularBytesField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._audioSpec {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Tts_V3_AudioContent, rhs: Speechkit_Tts_V3_AudioContent) -> Bool {
    if lhs.audioSource != rhs.audioSource {return false}
    if lhs._audioSpec != rhs._audioSpec {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Tts_V3_AudioFormatOptions: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".AudioFormatOptions"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "raw_audio"),
    2: .standard(proto: "container_audio"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Speechkit_Tts_V3_RawAudio?
        var hadOneofValue = false
        if let current = self.audioFormat {
          hadOneofValue = true
          if case .rawAudio(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.audioFormat = .rawAudio(v)
        }
      }()
      case 2: try {
        var v: Speechkit_Tts_V3_ContainerAudio?
        var hadOneofValue = false
        if let current = self.audioFormat {
          hadOneofValue = true
          if case .containerAudio(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.audioFormat = .containerAudio(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.audioFormat {
    case .rawAudio?: try {
      guard case .rawAudio(let v)? = self.audioFormat else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .containerAudio?: try {
      guard case .containerAudio(let v)? = self.audioFormat else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Tts_V3_AudioFormatOptions, rhs: Speechkit_Tts_V3_AudioFormatOptions) -> Bool {
    if lhs.audioFormat != rhs.audioFormat {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Tts_V3_RawAudio: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".RawAudio"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "audio_encoding"),
    2: .standard(proto: "sample_rate_hertz"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.audioEncoding) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.sampleRateHertz) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.audioEncoding != .unspecified {
      try visitor.visitSingularEnumField(value: self.audioEncoding, fieldNumber: 1)
    }
    if self.sampleRateHertz != 0 {
      try visitor.visitSingularInt64Field(value: self.sampleRateHertz, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Tts_V3_RawAudio, rhs: Speechkit_Tts_V3_RawAudio) -> Bool {
    if lhs.audioEncoding != rhs.audioEncoding {return false}
    if lhs.sampleRateHertz != rhs.sampleRateHertz {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Tts_V3_RawAudio.AudioEncoding: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "AUDIO_ENCODING_UNSPECIFIED"),
    1: .same(proto: "LINEAR16_PCM"),
  ]
}

extension Speechkit_Tts_V3_ContainerAudio: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".ContainerAudio"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "container_audio_type"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.containerAudioType) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.containerAudioType != .unspecified {
      try visitor.visitSingularEnumField(value: self.containerAudioType, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Tts_V3_ContainerAudio, rhs: Speechkit_Tts_V3_ContainerAudio) -> Bool {
    if lhs.containerAudioType != rhs.containerAudioType {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Tts_V3_ContainerAudio.ContainerAudioType: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "CONTAINER_AUDIO_TYPE_UNSPECIFIED"),
    1: .same(proto: "WAV"),
    2: .same(proto: "OGG_OPUS"),
    3: .same(proto: "MP3"),
  ]
}

extension Speechkit_Tts_V3_TextVariable: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".TextVariable"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "variable_name"),
    2: .standard(proto: "variable_value"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.variableName) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.variableValue) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.variableName.isEmpty {
      try visitor.visitSingularStringField(value: self.variableName, fieldNumber: 1)
    }
    if !self.variableValue.isEmpty {
      try visitor.visitSingularStringField(value: self.variableValue, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Tts_V3_TextVariable, rhs: Speechkit_Tts_V3_TextVariable) -> Bool {
    if lhs.variableName != rhs.variableName {return false}
    if lhs.variableValue != rhs.variableValue {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Tts_V3_AudioVariable: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".AudioVariable"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "variable_name"),
    2: .standard(proto: "variable_start_ms"),
    3: .standard(proto: "variable_length_ms"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.variableName) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.variableStartMs) }()
      case 3: try { try decoder.decodeSingularInt64Field(value: &self.variableLengthMs) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.variableName.isEmpty {
      try visitor.visitSingularStringField(value: self.variableName, fieldNumber: 1)
    }
    if self.variableStartMs != 0 {
      try visitor.visitSingularInt64Field(value: self.variableStartMs, fieldNumber: 2)
    }
    if self.variableLengthMs != 0 {
      try visitor.visitSingularInt64Field(value: self.variableLengthMs, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Tts_V3_AudioVariable, rhs: Speechkit_Tts_V3_AudioVariable) -> Bool {
    if lhs.variableName != rhs.variableName {return false}
    if lhs.variableStartMs != rhs.variableStartMs {return false}
    if lhs.variableLengthMs != rhs.variableLengthMs {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Tts_V3_UtteranceSynthesisResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".UtteranceSynthesisResponse"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "audio_chunk"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._audioChunk) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._audioChunk {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Tts_V3_UtteranceSynthesisResponse, rhs: Speechkit_Tts_V3_UtteranceSynthesisResponse) -> Bool {
    if lhs._audioChunk != rhs._audioChunk {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Tts_V3_AudioTemplate: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".AudioTemplate"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "audio"),
    2: .standard(proto: "text_template"),
    3: .same(proto: "variables"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._audio) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._textTemplate) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.variables) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._audio {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._textTemplate {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.variables.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.variables, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Tts_V3_AudioTemplate, rhs: Speechkit_Tts_V3_AudioTemplate) -> Bool {
    if lhs._audio != rhs._audio {return false}
    if lhs._textTemplate != rhs._textTemplate {return false}
    if lhs.variables != rhs.variables {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Tts_V3_AudioChunk: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".AudioChunk"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "data"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBytesField(value: &self.data) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.data.isEmpty {
      try visitor.visitSingularBytesField(value: self.data, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Tts_V3_AudioChunk, rhs: Speechkit_Tts_V3_AudioChunk) -> Bool {
    if lhs.data != rhs.data {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Tts_V3_TextTemplate: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".TextTemplate"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "text_template"),
    2: .same(proto: "variables"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.textTemplate) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.variables) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.textTemplate.isEmpty {
      try visitor.visitSingularStringField(value: self.textTemplate, fieldNumber: 1)
    }
    if !self.variables.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.variables, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Tts_V3_TextTemplate, rhs: Speechkit_Tts_V3_TextTemplate) -> Bool {
    if lhs.textTemplate != rhs.textTemplate {return false}
    if lhs.variables != rhs.variables {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Tts_V3_Hints: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".Hints"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "voice"),
    2: .standard(proto: "audio_template"),
    3: .same(proto: "speed"),
    4: .same(proto: "volume"),
    5: .same(proto: "role"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.hint != nil {try decoder.handleConflictingOneOf()}
          self.hint = .voice(v)
        }
      }()
      case 2: try {
        var v: Speechkit_Tts_V3_AudioTemplate?
        var hadOneofValue = false
        if let current = self.hint {
          hadOneofValue = true
          if case .audioTemplate(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.hint = .audioTemplate(v)
        }
      }()
      case 3: try {
        var v: Double?
        try decoder.decodeSingularDoubleField(value: &v)
        if let v = v {
          if self.hint != nil {try decoder.handleConflictingOneOf()}
          self.hint = .speed(v)
        }
      }()
      case 4: try {
        var v: Double?
        try decoder.decodeSingularDoubleField(value: &v)
        if let v = v {
          if self.hint != nil {try decoder.handleConflictingOneOf()}
          self.hint = .volume(v)
        }
      }()
      case 5: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.hint != nil {try decoder.handleConflictingOneOf()}
          self.hint = .role(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.hint {
    case .voice?: try {
      guard case .voice(let v)? = self.hint else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 1)
    }()
    case .audioTemplate?: try {
      guard case .audioTemplate(let v)? = self.hint else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case .speed?: try {
      guard case .speed(let v)? = self.hint else { preconditionFailure() }
      try visitor.visitSingularDoubleField(value: v, fieldNumber: 3)
    }()
    case .volume?: try {
      guard case .volume(let v)? = self.hint else { preconditionFailure() }
      try visitor.visitSingularDoubleField(value: v, fieldNumber: 4)
    }()
    case .role?: try {
      guard case .role(let v)? = self.hint else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 5)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Tts_V3_Hints, rhs: Speechkit_Tts_V3_Hints) -> Bool {
    if lhs.hint != rhs.hint {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Tts_V3_UtteranceSynthesisRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".UtteranceSynthesisRequest"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "model"),
    2: .same(proto: "text"),
    3: .standard(proto: "text_template"),
    4: .same(proto: "hints"),
    5: .standard(proto: "output_audio_spec"),
    6: .standard(proto: "loudness_normalization_type"),
    7: .standard(proto: "unsafe_mode"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.model) }()
      case 2: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.utterance != nil {try decoder.handleConflictingOneOf()}
          self.utterance = .text(v)
        }
      }()
      case 3: try {
        var v: Speechkit_Tts_V3_TextTemplate?
        var hadOneofValue = false
        if let current = self.utterance {
          hadOneofValue = true
          if case .textTemplate(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.utterance = .textTemplate(v)
        }
      }()
      case 4: try { try decoder.decodeRepeatedMessageField(value: &self.hints) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._outputAudioSpec) }()
      case 6: try { try decoder.decodeSingularEnumField(value: &self.loudnessNormalizationType) }()
      case 7: try { try decoder.decodeSingularBoolField(value: &self.unsafeMode) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.model.isEmpty {
      try visitor.visitSingularStringField(value: self.model, fieldNumber: 1)
    }
    switch self.utterance {
    case .text?: try {
      guard case .text(let v)? = self.utterance else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    }()
    case .textTemplate?: try {
      guard case .textTemplate(let v)? = self.utterance else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case nil: break
    }
    if !self.hints.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.hints, fieldNumber: 4)
    }
    try { if let v = self._outputAudioSpec {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    if self.loudnessNormalizationType != .unspecified {
      try visitor.visitSingularEnumField(value: self.loudnessNormalizationType, fieldNumber: 6)
    }
    if self.unsafeMode != false {
      try visitor.visitSingularBoolField(value: self.unsafeMode, fieldNumber: 7)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speechkit_Tts_V3_UtteranceSynthesisRequest, rhs: Speechkit_Tts_V3_UtteranceSynthesisRequest) -> Bool {
    if lhs.model != rhs.model {return false}
    if lhs.utterance != rhs.utterance {return false}
    if lhs.hints != rhs.hints {return false}
    if lhs._outputAudioSpec != rhs._outputAudioSpec {return false}
    if lhs.loudnessNormalizationType != rhs.loudnessNormalizationType {return false}
    if lhs.unsafeMode != rhs.unsafeMode {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speechkit_Tts_V3_UtteranceSynthesisRequest.LoudnessNormalizationType: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "LOUDNESS_NORMALIZATION_TYPE_UNSPECIFIED"),
    1: .same(proto: "MAX_PEAK"),
    2: .same(proto: "LUFS"),
  ]
}
